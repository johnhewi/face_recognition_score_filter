{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnhewi/face_recognition_score_filter/blob/main/ImageScore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"6\" color=\"orange\">Facial Recognition Filtering Tool</font>\n",
        "\n",
        "This tool allows the user to create a facial recognition model from a set of images. The model can then be used to analyze another set of images and score each photo on its similarity to the model. The list of scores can then be used to filter the image files by score."
      ],
      "metadata": {
        "id": "4GbEntEe2E3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font size=\"4\" color=\"orange\">Mount Drive and Install Dependencies (GPU Runtime Required)</font>\n",
        "#@markdown #### Mount Google Drive and then Install Necessary Packages (GPU Runtime Required)\n",
        "#@markdown\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# isntall necessary packages\n",
        "\n",
        "!pip install dlib\n",
        "!pip install face_recognition\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DFmvanWf9iz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font size=\"4\" color=\"orange\">Create Model</font>\n",
        "#@markdown Create a facial recognition model from a set of photos. (If you already have a .npy file you'd like to use, you can skip this step) You will need to enter the path to the folder that contains the images you want to use to train your facial recognition model. Additionally, you will need to select the path to the folder where you want the model to be stored. Finally, you must pick a name for the model file itself.\n",
        "# Import necessary libraries\n",
        "#@markdown <br><br>\n",
        "#@markdown <br>\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "from google.colab import drive\n",
        "from shutil import copy\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "#@markdown ##### training_dir: folder of images with known subject\n",
        "\n",
        "# Define the paths to the training and test dataset directories\n",
        "training_dir = '' #@param {type:\"string\"}\n",
        "#@markdown ##### model_dir: folder where model is to be stored\n",
        "model_dir = '' #@param {type:\"string\"}\n",
        "#@markdown ##### model_name: name your model\n",
        "model_name = 'facial_recognition_model_1' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "# Get the list of training images\n",
        "training_images_paths = [os.path.join(training_dir, f) for f in os.listdir(training_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# Load and encode each training image\n",
        "model_encodings = []\n",
        "for path in training_images_paths:\n",
        "   # Load the image from file path\n",
        "    image = Image.open(path)\n",
        "\n",
        "    # If the image has an alpha channel, remove it\n",
        "    if image.mode == 'RGBA':\n",
        "        print(\"removing alpha channel...\")\n",
        "        image = image.convert('RGB')\n",
        "    print(f\"Loaded {path}, checking for faces...\")\n",
        "\n",
        "    # Convert the image to a NumPy array\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    # Check if the image contains any faces\n",
        "    face_locations = face_recognition.face_locations(image_array)\n",
        "\n",
        "    # If the image contains faces, encode the faces\n",
        "    if face_locations:\n",
        "        print(f\"Found {len(face_locations)} faces in {path}, adding to model...\")\n",
        "        encoding = face_recognition.face_encodings(image_array, known_face_locations=face_locations)[0]\n",
        "        model_encodings.append(encoding)\n",
        "\n",
        "# Calculate the average encoding\n",
        "print(f\"Calculating average encoding for {os.path.basename(training_dir)}...\")\n",
        "average_encoding = np.mean(model_encodings, axis=0)\n",
        "print(f\"Average encoding for {model_name}: {average_encoding}\")\n",
        "\n",
        "# Save the average encoding to a file\n",
        "np.save(os.path.join(model_dir, f\"{model_name}.npy\"), average_encoding)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uqnrcjlfxw9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irqiaf6H5xtL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "#@title <font size=\"4\" color=\"orange\">Test Images Against Model</font>\n",
        "#@markdown Create the similarity scores for a set of images using the facial recognition model created in a previous step. You will need to input the filepath to your facial recognition model, the filepath to the directory containing the images you want to generate similarity scores for, whether or not you want to search all subdirectories (select \"search_recursively\"), your desired name for the file containing the similarity score and the filepath to the directory where you want the similarity score file saved. <br> If you search the directory recurively, a similarity score file will be created in all subdirectories containing image files. (.jpg or .png) A file containing the similarity scores for all the images will also be created and placed in the directory you specify.\n",
        "\n",
        "\n",
        "#@markdown ##### model_file_path: Path of model to be tested against\n",
        "model_file_path = '' #@param {type:\"string\"}\n",
        "\n",
        "# Load the model (average encoding)\n",
        "average_encoding = np.load(model_file_path)\n",
        "\n",
        "#@markdown ##### test_dir: folder of images with test images to be scored\n",
        "test_dir = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##### search_recursively: Search test_dir recursively\n",
        "search_recursively = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Initialize a dictionary to store the similarity scores\n",
        "similarity_scores = {}\n",
        "\n",
        "#@markdown ##### output_file_name: Name of image score file\n",
        "output_file_name = 'similarity_scores' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##### output_file_path: Path to store image score file\n",
        "output_file_path = '' #@param {type:\"string\"}\n",
        "\n",
        "# Join the output_file_path and output_file_name to create the full path\n",
        "full_output_file_path = os.path.join(output_file_path, output_file_name)\n",
        "\n",
        "# Function to recursively get all image files from a directory\n",
        "def get_all_image_files(directory, recursive):\n",
        "    image_files = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.png'):\n",
        "                image_files.append(os.path.join(root, file))\n",
        "        if not recursive:\n",
        "            break\n",
        "    return image_files\n",
        "\n",
        "def get_processed_files(directory):\n",
        "    \"\"\"\n",
        "    Check if a similarity_scores.txt file exists in the given directory.\n",
        "    If it exists, read the file and extract the filenames listed in it.\n",
        "    Return a set containing the filenames.\n",
        "    \"\"\"\n",
        "    processed_files = set()\n",
        "    scores_file_path = os.path.join(directory, \"similarity_scores.txt\")\n",
        "\n",
        "    if os.path.exists(scores_file_path):\n",
        "        with open(scores_file_path, 'r') as scores_file:\n",
        "            for line in scores_file:\n",
        "                # Extract the filename from each line in the file\n",
        "                filename = line.split(\":\")[0].strip()\n",
        "                processed_files.add(filename)\n",
        "\n",
        "    return processed_files\n",
        "\n",
        "# Get the list of test images\n",
        "test_images_paths = get_all_image_files(test_dir, search_recursively)\n",
        "\n",
        "# Display the number of image files found\n",
        "num_images = len(test_images_paths)\n",
        "print(f\"Number of image files found: {num_images}\")\n",
        "\n",
        "# Initialize the start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Initialize a dictionary to store the similarity scores for each subdirectory\n",
        "subdirectory_scores = {}\n",
        "\n",
        "# Compare each test image with the average encoding and calculate similarity scores\n",
        "current_subdirectory = None\n",
        "\n",
        "# Initialize a set to store the names of processed files for the current subdirectory\n",
        "processed_files = set()\n",
        "\n",
        "# Compare each test image with the average encoding and calculate similarity scores\n",
        "for idx, path in enumerate(test_images_paths, start=1):\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"File not found: {path}, skipping...\")\n",
        "\n",
        "    # Extract the subdirectory from the path\n",
        "    subdirectory = os.path.dirname(path)\n",
        "\n",
        "    # Check if the subdirectory has changed\n",
        "    if subdirectory != current_subdirectory:\n",
        "        processed_files = get_processed_files(subdirectory)\n",
        "\n",
        "    # Check if the file has been processed before and skip it if it has\n",
        "    if path in processed_files:\n",
        "        print(f\"File {path} has already been processed, skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Load a test image\n",
        "    test_image = face_recognition.load_image_file(path)\n",
        "\n",
        "    # Encode the test image to get the facial features\n",
        "    encodings = face_recognition.face_encodings(test_image)\n",
        "\n",
        "    # Check if any face is detected\n",
        "    if len(encodings) == 0:\n",
        "        print(f\"No faces found in {path}, skipping...\")\n",
        "        continue\n",
        "\n",
        "    test_encoding = encodings[0]\n",
        "\n",
        "    # Compute the Euclidean distance between the average encoding and the test encoding\n",
        "    distance = face_recognition.face_distance([average_encoding], test_encoding)\n",
        "    similarity_score = 1 / (1 + distance)  # Convert distance to similarity score\n",
        "\n",
        "    # Print the similarity score\n",
        "    print(f\"Similarity score for {path}: {similarity_score[0]}\")\n",
        "\n",
        "    # Store the similarity score in the dictionary using the full file path\n",
        "    similarity_scores[path] = similarity_score[0]\n",
        "\n",
        "\n",
        "\n",
        "    # Check if the subdirectory has changed\n",
        "    if subdirectory != current_subdirectory:\n",
        "        # If it's not the first iteration, write the scores of the previous subdirectory to a file\n",
        "        if current_subdirectory is not None:\n",
        "            subdirectory_file_path = os.path.join(current_subdirectory, \"similarity_scores.txt\")\n",
        "            with open(subdirectory_file_path, 'w') as subdirectory_file:\n",
        "                for image_path, score in subdirectory_scores[current_subdirectory].items():\n",
        "                    subdirectory_file.write(f\"{image_path}: {score}\\n\")\n",
        "            print(f\"Similarity scores for {current_subdirectory} saved to {subdirectory_file_path}\")\n",
        "\n",
        "        # Update the current subdirectory and clear the scores for the new subdirectory\n",
        "        current_subdirectory = subdirectory\n",
        "        subdirectory_scores[current_subdirectory] = {}\n",
        "\n",
        "    # Store the similarity score in the subdirectory_scores dictionary\n",
        "    subdirectory_scores[current_subdirectory][path] = similarity_score[0]\n",
        "\n",
        "    # Calculate and print the estimated time remaining\n",
        "    elapsed_time = time.time() - start_time\n",
        "    avg_time_per_image = elapsed_time / idx\n",
        "    remaining_images = num_images - idx\n",
        "    estimated_time_remaining = avg_time_per_image * remaining_images\n",
        "    print(f\"Estimated time remaining: {estimated_time_remaining:.2f} seconds\")\n",
        "\n",
        "# After the loop, write the similarity scores of the last subdirectory to a file\n",
        "if current_subdirectory is not None:\n",
        "    subdirectory_file_path = os.path.join(current_subdirectory, \"similarity_scores.txt\")\n",
        "    with open(subdirectory_file_path, 'w') as subdirectory_file:\n",
        "        for image_path, score in subdirectory_scores[current_subdirectory].items():\n",
        "            subdirectory_file.write(f\"{image_path}: {score}\\n\")\n",
        "    print(f\"Similarity scores for {current_subdirectory} saved to {subdirectory_file_path}\")\n",
        "\n",
        "\n",
        "# Write the similarity scores to a file\n",
        "with open(full_output_file_path, 'w') as output_file:\n",
        "    for image_path, score in similarity_scores.items():\n",
        "        output_file.write(f\"{image_path}: {score}\\n\")\n",
        "\n",
        "print(f\"Similarity scores saved to {full_output_file_path}. (Similiarity scores for each subdirectory saved in each subdirectory as well)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "#@title <font size=\"4\" color=\"orange\">Compile and Analyze Similarity Scores</font>\n",
        "\n",
        "#@markdown ##### <b>directory</b>: Path of directory containing photos or subfolders. Will look for similarity_scores.txt in all subdirectories. These will have been created automatically if you tested images against model recursively in previous step.\n",
        "directory = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##### search_recursively: Search all subfolders for folders with a similarity_scores.txt file\n",
        "search_recursively = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ##### similarity_scores_file_path: If you are not searching recursively, specify a path to the similarity scores file\n",
        "similarity_scores_file_path = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##### output_file_path: The directory where the analysis file will be written\n",
        "output_file_path = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##### output_file_name: The name of the file with the analyis\n",
        "analysis_file_name = 'analysis_file' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "# Function to recursively get all similarity scores files and read them\n",
        "def get_all_similarity_scores(directory):\n",
        "    scores = {}\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if \"similarity_scores.txt\" in files:\n",
        "            with open(os.path.join(root, \"similarity_scores.txt\"), 'r') as scores_file:\n",
        "                for line in scores_file:\n",
        "                    parts = line.strip().split(\":\")\n",
        "                    scores[parts[0].strip()] = float(parts[1].strip())\n",
        "    return scores\n",
        "\n",
        "if search_recursively:\n",
        "    # Fetch all the similarity scores\n",
        "    similarity_scores = get_all_similarity_scores(directory)\n",
        "else:\n",
        "    similarity_scores = {}\n",
        "    with open(similarity_scores_file_path, 'r') as scores_file:\n",
        "        for line in scores_file:\n",
        "            parts = line.strip().split(\":\")\n",
        "\n",
        "\n",
        "# Calculate various statistics\n",
        "max_score = max(similarity_scores.values())\n",
        "min_score = min(similarity_scores.values())\n",
        "average_score = np.mean(list(similarity_scores.values()))\n",
        "median_score = np.median(list(similarity_scores.values()))\n",
        "std_dev_score = np.std(list(similarity_scores.values()))\n",
        "number_of_scores = len(similarity_scores)\n",
        "\n",
        "# Calculate the percentiles\n",
        "percentiles = {percentile: np.percentile(list(similarity_scores.values()), percentile) for percentile in range(0, 101)}\n",
        "\n",
        "# Preparing the statistics string\n",
        "stats_str = f\"Statistics for file {directory} \\n \\n\"\n",
        "stats_str += f\"Number of Files/Scores: {number_of_scores}\\n\"\n",
        "stats_str += f\"Max Score: {max_score}\\nMin Score: {min_score}\\nAverage Score: {average_score}\\n\"\n",
        "stats_str += f\"Median Score: {median_score}\\nStandard Deviation: {std_dev_score}\\n\"\n",
        "stats_str += \"\\nPercentiles:\\n\"\n",
        "\n",
        "for percentile, score in percentiles.items():\n",
        "    # Counting how many scores are above or equal to, and below or equal to the current percentile value\n",
        "    above_or_equal_count = sum(1 for val in similarity_scores.values() if val >= score)\n",
        "    below_or_equal_count = sum(1 for val in similarity_scores.values() if val <= score)\n",
        "\n",
        "        # Calculating how many standard deviations away from the mean the current percentile value is\n",
        "    z_score = (score - average_score) / std_dev_score\n",
        "\n",
        "    # Adding the percentile value, score, and counts to the statistics string\n",
        "    stats_str += f\"{percentile}th Percentile: {score}, Above or Equal: {above_or_equal_count}, Below or Equal: {below_or_equal_count}, {z_score} std dv from mean\\n\"\n",
        "\n",
        "# Print the statistics\n",
        "print(stats_str)\n",
        "\n",
        "# Save the statistics to a file\n",
        "analysis_file_path = os.path.join(output_file_path, analysis_file_name)\n",
        "with open(analysis_file_path, 'w') as file:\n",
        "    file.write(stats_str)\n",
        "\n",
        "print(f\"Statistics saved to {output_file_path}\")"
      ],
      "metadata": {
        "id": "t2_DOKECLZdD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title <font size=\"4\" color=\"orange\">Filter Files by Similarity Score</font>\n",
        "\n",
        "#@markdown ##### <b>directory</b>: Path of directory containing photos or subfolders. Will look for similarity_scores.txt in all subdirectories. These will have been created automatically if you tested images against model recursively in previous step.\n",
        "directory = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##### search_recursively: Search all subfolders for folders with a similarity_scores.txt file\n",
        "search_recursively = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ##### similarity_scores_file_path: If you are not searching recursively, specify a path to the similarity scores file\n",
        "similarity_scores_file_path = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##### minimum_percentile: the minimum percentile for filepaths in the list\n",
        "minimum_percentile = 90 #@param {type:\"number\"}\n",
        "minimum_percentile = float(minimum_percentile)\n",
        "\n",
        "#@markdown ##### maximum_percentile: the maximum percentile for filepaths in the list\n",
        "maximum_percentile = 100 #@param {type:\"number\"}\n",
        "maximum_percentile = float(maximum_percentile)\n",
        "\n",
        "#@markdown ##### filter_by_score: Select to filter files by similarity score. If unchecked, images will be filtered by percentile.\n",
        "filter_by_score = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ##### minimum_similarity_score: the minimum similarity score for filepaths in the list\n",
        "minimum_similarity_score = 0 #@param {type:\"number\"}\n",
        "minimum_similarity_score = float(minimum_similarity_score)\n",
        "\n",
        "#@markdown ##### maximum_similarity_score: the maximum percentile for filepaths in the list\n",
        "maximum_similarity_score = 1 #@param {type:\"number\"}\n",
        "maximum_similarity_score = float(maximum_similarity_score)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown ##### output_file_path: The directory where the file listing filtered images will be written\n",
        "output_file_path = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##### output_file_name: The name of the file with the list of top percentile files\n",
        "output_file_name = 'filtered_filepaths_and_scores' #@param {type:\"string\"}\n",
        "\n",
        "# Function to recursively get all similarity scores files and read them\n",
        "def get_all_similarity_scores(directory):\n",
        "    scores = {}\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if \"similarity_scores.txt\" in files:\n",
        "            with open(os.path.join(root, \"similarity_scores.txt\"), 'r') as scores_file:\n",
        "                for line in scores_file:\n",
        "                    parts = line.strip().split(\":\")\n",
        "                    scores[parts[0].strip()] = float(parts[1].strip())\n",
        "    return scores\n",
        "\n",
        "if search_recursively:\n",
        "    # Fetch all the similarity scores\n",
        "    similarity_scores = get_all_similarity_scores(directory)\n",
        "else:\n",
        "    similarity_scores = {}\n",
        "    with open(similarity_scores_file_path, 'r') as scores_file:\n",
        "        for line in scores_file:\n",
        "            parts = line.strip().split(\":\")\n",
        "\n",
        "# Check whether to filter by score or by percentile\n",
        "if filter_by_score:\n",
        "    # Filter images whose similarity scores are within the score boundaries\n",
        "    filtered_images = {\n",
        "        image_path: score for image_path, score in similarity_scores.items()\n",
        "        if minimum_similarity_score <= score <= maximum_similarity_score\n",
        "    }\n",
        "else:\n",
        "    # Calculate the minimum and maximum percentile thresholds\n",
        "    min_percentile_threshold = np.percentile(list(similarity_scores.values()), minimum_percentile)\n",
        "    max_percentile_threshold = np.percentile(list(similarity_scores.values()), maximum_percentile)\n",
        "\n",
        "    # Filter images whose similarity scores are within the percentile boundaries\n",
        "    filtered_images = {\n",
        "        image_path: score for image_path, score in similarity_scores.items()\n",
        "        if min_percentile_threshold <= score <= max_percentile_threshold\n",
        "    }\n",
        "\n",
        "# Save this list to a file\n",
        "top_images_file_path = os.path.join(output_file_path, output_file_name)\n",
        "\n",
        "with open(top_images_file_path, 'w') as file:\n",
        "    for image_path, score in filtered_images.items():\n",
        "        file.write(f\"{image_path}: {score}\\n\")\n",
        "\n",
        "print(f\"Filtered files saved to {top_images_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "wW0_c0MnYbDG",
        "outputId": "e2bdbdf9-8fd6-435f-bc50-c101a423d78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered files saved to /content/drive/MyDrive/ImageScore/avgncle/avgscores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "#@title <font size=\"4\" color=\"orange\">Move Filtered Images</font>\n",
        "\n",
        "#@markdown ##### filtered_images_file_path: Path of the file containing the list of filtered images\n",
        "filtered_images_file_path = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ##### destination_dir: Path of the directory to move the images to\n",
        "destination_dir = '' #@param {type:\"string\"}\n",
        "\n",
        "# Ensure the destination directory exists\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "# Read the file containing the list of top percentile images\n",
        "with open(top_images_file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Iterate through each line in the file\n",
        "for line in lines:\n",
        "    # Extract the full image path from the line\n",
        "    source_path = line.split(':')[0].strip()\n",
        "\n",
        "    # Check if the source file exists\n",
        "    if not os.path.exists(source_path):\n",
        "        print(f\"Warning: Source file does not exist at {source_path}\")\n",
        "        continue\n",
        "\n",
        "    # Define the destination path of the image\n",
        "    destination_path = os.path.join(destination_dir, os.path.basename(source_path))\n",
        "\n",
        "    # Move the image from the source path to the destination path\n",
        "    shutil.move(source_path, destination_path)\n",
        "\n",
        "    print(f\"{os.path.basename(source_path)} has been moved to {destination_dir}\")\n"
      ],
      "metadata": {
        "id": "7jGnQ2XrZAe0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
